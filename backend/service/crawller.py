import requests
import re

import time
import random
import json
import os
from dotenv import load_dotenv
from bs4 import BeautifulSoup
from flask import Flask, jsonify, request
from flask_cors import CORS
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# Bi·∫øn global ƒë·ªÉ l∆∞u tr·ªØ t·∫•t c·∫£ c√°c b·∫£n ghi ƒë√£ c√†o trong b·ªô nh·ªõ
SCRAPED_DATA_STORE = []

# ----------------- C√ÅC H√ÄM UTILITY/SCRAPER -----------------
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_8 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
]


def get_random_header(referer_url=None):
    """T·∫°o header ng·∫´u nhi√™n."""
    headers = {
        'User-Agent': random.choice(USER_AGENTS),
        'x-api-source': 'web',
    }
    if referer_url:
        # ƒê·∫£m b·∫£o referer_url ch·ªâ ch·ª©a c√°c k√Ω t·ª± an to√†n cho header (ASCII)
        try:
            headers['Referer'] = referer_url.encode('latin-1', 'ignore').decode('latin-1')
        except Exception:
            # D√πng URL c∆° b·∫£n n·∫øu vi·ªác m√£ h√≥a th·∫•t b·∫°i
            headers['Referer'] = "https://tiki.vn"
    return headers


def extract_tiki_product_id(url):
    """Tr√≠ch xu·∫•t product_id t·ª´ URL s·∫£n ph·∫©m Tiki."""
    regex = r"p(\d+)\.html"
    match = re.search(regex, url)
    if match:
        return int(match.group(1))
    return None


def fetch_product_data(product_id, referer_url, max_retries=3):
    api_url = f"https://tiki.vn/api/v2/products/{product_id}?platform=web"
    for attempt in range(max_retries):
        dynamic_headers = get_random_header(referer_url)
        try:
            response = requests.get(api_url, headers=dynamic_headers, timeout=10)
            response.raise_for_status()
            print(f"L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m th√†nh c√¥ng ·ªü l·∫ßn th·ª≠ th·ª© {attempt + 1}")
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"L·ªói l·∫ßn th·ª≠ {attempt + 1} cho ID {product_id}: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
            else:
                print("ƒê√£ h·∫øt s·ªë l·∫ßn th·ª≠ l·∫°i.")
                return None
    return None
def fetch_reviews_data(product_id, desired_total=20, per_page=20, sleep_between=0.5, max_retries=3):
    collected = []
    page = 1
    while len(collected) < desired_total:
        api_url = (
            f"https://tiki.vn/api/v2/reviews?"
            f"product_id={product_id}&page={page}&limit={per_page}"
            f"&include=comments,contribute_info,attribute_vote_summary,attribute_vote_stats"
            f"&sort=score_desc,created_at%20desc"
        )
        success = False
        for attempt in range(max_retries):
            try:
                resp = requests.get(api_url, headers=get_random_header(), timeout=10)
                resp.raise_for_status()
                j = resp.json()
                success = True
                break
            except requests.exceptions.RequestException as e:
                print(f"‚ùå L·ªói l·∫ßn th·ª≠ {attempt + 1} khi l·∫•y review trang {page}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                else:
                    print(f"üí• ƒê√£ h·∫øt s·ªë l·∫ßn th·ª≠ l·∫°i cho review trang {page}.")
                    return collected
        if not success:
            break
        page_items = j.get("data") or j.get("reviews") or []
        if not page_items:
            print(f"‚ö†Ô∏è H·∫øt d·ªØ li·ªáu ·ªü trang {page}.")
            break
        collected.extend(page_items)
        print(f"‚úÖ L·∫•y ƒë∆∞·ª£c {len(page_items)} b√¨nh lu·∫≠n ·ªü trang {page} (T·ªïng: {len(collected)})")
        if len(collected) >= desired_total or len(page_items) < per_page:
            break
        page += 1
        time.sleep(sleep_between)
    print(f"üéØ T·ªïng c·ªông l·∫•y ƒë∆∞·ª£c {len(collected)} b√¨nh lu·∫≠n.")
    return collected[:desired_total]


def parse_product_to_json(data):
    if not data:
        return {}
    current_seller = data.get("current_seller", {})
    store_url = f"{current_seller['link']}" if current_seller and current_seller.get('link') else None

    description_html = data.get("description", "")
    soup = BeautifulSoup(description_html, "html.parser")
    description_text = soup.get_text(separator="\n", strip=True)

    highlight_items = data.get("highlight", {}).get("items", [])

    specs = [{"name": a["name"], "value": a["value"]}
             for s in data.get("specifications", [])
             for a in s.get("attributes", [])]

    gallery = [img["base_url"] for img in data.get("images", []) if img.get("base_url")]

    description_imgs = [link for link in description_html.split('"')
                        if link.startswith("https") and (
                                link.endswith(".jpg") or link.endswith(".png") or link.endswith(".webp"))]

    return {
        "product_id": data.get("id"),
        "name": data.get("name"),
        "brand": data.get("brand", {}).get("name"),
"price": data.get("price"),
        "rating_average": data.get("rating_average"),
        "review_count": data.get("review_count"),
        "sold_quantity": data.get("all_time_quantity_sold"),
        "store_url": store_url,
        "highlights": highlight_items,
        "specifications": specs,
        "description_text": description_text,
        "gallery_images": gallery,
        "description_images": description_imgs,
    }


def extract_next_value(keyword, all_text):
    lines = all_text.split("\n")
    for i, line in enumerate(lines):
        if keyword in line:
            for j in range(i + 1, len(lines)):
                val = lines[j].strip()
                if val:
                    return val
    return "Kh√¥ng c√≥ d·ªØ li·ªáu"


def fetch_store_data_selenium(url):
    if not url:
        return {"error": "Kh√¥ng c√≥ URL c·ª≠a h√†ng ƒë·ªÉ c√†o."}

    print(f"üõ†Ô∏è B·∫Øt ƒë·∫ßu c√†o d·ªØ li·ªáu c·ª≠a h√†ng b·∫±ng Selenium cho URL: {url}")
    options = Options()
    options.add_argument("--headless")  # Ch·∫°y ·∫©n ƒë·ªÉ kh√¥ng th·∫•y c·ª≠a s·ªï tr√¨nh duy·ªát
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument(f"user-agent={random.choice(USER_AGENTS)}")

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o WebDriver: {e}")
        return {"error": "L·ªói kh·ªüi t·∫°o WebDriver. ƒê·∫£m b·∫£o Chromedriver ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë√∫ng c√°ch."}

    try:
        final_url = url
        if '?' not in url:
            final_url = f"{url}?t=storeInfo"
        elif 't=' not in url:
            final_url = f"{url}&t=storeInfo"

        driver.get(final_url)
        print("‚è≥ Ch·ªù 5 gi√¢y ƒë·ªÉ t·∫£i n·ªôi dung JavaScript...")
        time.sleep(5)

        soup = BeautifulSoup(driver.page_source, "html.parser")

        store_name_tag = soup.find('h1')
        store_name = store_name_tag.get_text(strip=True) if store_name_tag else "Kh√¥ng c√≥ d·ªØ li·ªáu"

        all_text = soup.get_text(separator="\n")

        followers = "0"
        chat_response = "Ch∆∞a c√≥"
        spans = soup.find_all("span")
        for i, span in enumerate(spans):
            text = span.get_text(strip=True)
            if text == "Ng∆∞·ªùi theo d√µi" and i + 1 < len(spans):
                followers = spans[i + 1].get_text(strip=True)
            if text == "Ph·∫£n h·ªìi Chat" and i + 1 < len(spans):
                chat_response = spans[i + 1].get_text(strip=True)

        data = {
            "store_name": store_name,
            "member_since": extract_next_value("Th√†nh vi√™n t·ª´ nƒÉm", all_text),
            "products_count": extract_next_value("S·∫£n ph·∫©m", all_text),
            "store_description": extract_next_value("M√¥ t·∫£ c·ª≠a h√†ng", all_text),
"rating_score": extract_next_value("ƒê√°nh gi√°", all_text),
            "followers": followers,
            "chat_response_rate": chat_response
        }
        print("‚úÖ L·∫•y d·ªØ li·ªáu c·ª≠a h√†ng th√†nh c√¥ng.")
        return data

    except Exception as e:
        print(f"‚ùå L·ªói khi c√†o d·ªØ li·ªáu c·ª≠a h√†ng: {e}")
        return {"error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi c√†o d·ªØ li·ªáu c·ª≠a h√†ng: {e}"}

    finally:
        try:
            driver.quit()
            print("Driver ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.")
        except NameError:
            pass

        # ----------------- H√ÄM L∆ØU & L·∫§Y D·ªÆ LI·ªÜU GLOBAL -----------------


def save_to_global_store( url, data):
    """X√≥a t·∫•t c·∫£ d·ªØ li·ªáu c≈© trong Global Store v√† ch·ªâ l∆∞u b·∫£n ghi m·ªõi nh·∫•t."""
    global SCRAPED_DATA_STORE

    # X√≥a to√†n b·ªô d·ªØ li·ªáu c≈© (ƒê·∫£m b·∫£o ch·ªâ gi·ªØ l·∫°i 1 b·∫£n ghi m·ªõi nh·∫•t)
    SCRAPED_DATA_STORE.clear()

    data_to_save = {
        "url": url,
        "information": data
    }

    # Th√™m b·∫£n ghi m·ªõi
    SCRAPED_DATA_STORE.append(data_to_save)
    print(f"üíæ X√≥a d·ªØ li·ªáu c≈© v√† L∆∞u b·∫£n ghi m·ªõi  v√†o Global Store th√†nh c√¥ng.")
    return True


def get_all_scraped_data_from_global():
    """L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ l∆∞u t·ª´ bi·∫øn global."""
    global SCRAPED_DATA_STORE
    return SCRAPED_DATA_STORE.copy()


# ----------------- FLASK API LOGIC C·ªêT L√ïI -----------------

def process_tiki_url(tiki_url):
    """
    H√†m logic c·ªët l√µi: L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m, ƒë√°nh gi√° v√† c·ª≠a h√†ng t·ª´ m·ªôt URL Tiki.
    Tr·∫£ v·ªÅ dictionary d·ªØ li·ªáu v√† status code.
    """
    if not tiki_url:
        return {"error": "Vui l√≤ng cung c·∫•p URL s·∫£n ph·∫©m Tiki."}, 400

    product_id = extract_tiki_product_id(tiki_url)
    if not product_id:
        return {"error": "Kh√¥ng th·ªÉ l·∫•y product_id t·ª´ URL cung c·∫•p."}, 400

    # 1. L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m
    product_data = fetch_product_data(product_id, tiki_url)
    if not product_data:
        return {"error": "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m t·ª´ API Tiki."}, 500

    parsed_product = parse_product_to_json(product_data)
    # 2. L·∫•y d·ªØ li·ªáu ƒë√°nh gi√°
    reviews = fetch_reviews_data(product_id, desired_total=20)

    # 3. L·∫•y d·ªØ li·ªáu c·ª≠a h√†ng
    store_url = parsed_product.get("store_url")
    store_data = {}
    if store_url:
        final_store_url = f"{store_url}?t=storeInfo" if '?' not in store_url else f"{store_url}&t=storeInfo"
        # Gi·∫£ ƒë·ªãnh fetch_store_data_selenium ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a
        store_data_raw = fetch_store_data_selenium(final_store_url)
        store_data = {"store_data": store_data_raw}
    else:
        store_data = {"store_data": {"error": "Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ª≠a h√†ng."}}

    # 4. X√¢y d·ª±ng k·∫øt qu·∫£ cu·ªëi c√πng

    # Kh·ªüi t·∫°o danh s√°ch properties t·ª´ specs
    product_properties = [f"{spec['name']}: {spec['value']}" for spec in parsed_product.get("specifications", [])]

    # üîë S·ª¨A L·ªñI C√ö PH√ÅP: Th√™m c√°c tr∆∞·ªùng c·ªët l√µi v√†o danh s√°ch properties d∆∞·ªõi d·∫°ng chu·ªói
    product_properties.append(f"price: {parsed_product.get('price')}")
    product_properties.append(f"rating_average: {parsed_product.get('rating_average')}")
    product_properties.append(f"review_count: {parsed_product.get('review_count')}")
    product_properties.append(f"sold_quantity: {parsed_product.get('sold_quantity')}")

    image_buyer_urls = list({
        img["full_path"]
        for r in reviews
        for img in r.get("images", [])
        if img.get("full_path")
    })

    result = {
        **store_data,
        "name": parsed_product.get("name"),
        "description": parsed_product.get("description_text"),
        "properties": product_properties,  # CH·ª®A C·∫¢ TH√îNG TIN C·ªêT L√ïI V√Ä SPECS
        "image_product": parsed_product.get("description_images", []) + parsed_product.get("gallery_images", []),
        "image_buyer": image_buyer_urls,
        "reviews": [
            {
                "rating": r.get("rating"),
                "title": r.get("title"),
                "content": r.get("content"),
            }
            for r in reviews
        ]
    }

    return result, 200

# ... (H√†m extract_core_metrics gi·ªØ nguy√™n nh∆∞ b·∫°n cung c·∫•p) ...

def extract_core_metrics(result_data: dict) -> dict:
    properties_list = result_data.get('properties', [])
    metrics = {
        'price': None,
        'rating_average': None,
        'review_count': None,
        'sold_quantity': None,
    }

    # Duy·ªát qua t·ª´ng chu·ªói trong danh s√°ch properties
    for prop_str in properties_list:
        try:
            # Ph√¢n t√°ch th√†nh key v√† value
            key, value_str = prop_str.split(':', 1)
            key = key.strip()
            value_str = value_str.strip()

            # X·ª≠ l√Ω v√† l∆∞u gi√° tr·ªã
            if key == 'price':
                # Chuy·ªÉn sang s·ªë nguy√™n (lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i s·ªë)
                metrics['price'] = int(''.join(filter(str.isdigit, value_str)))
            elif key == 'rating_average':
                # Chuy·ªÉn sang s·ªë th·ª±c
                metrics['rating_average'] = float(value_str)
            elif key == 'review_count':
                metrics['review_count'] = int(value_str)
            elif key == 'sold_quantity':
                metrics['sold_quantity'] = int(value_str)

        except (ValueError, IndexError):
            # B·ªè qua c√°c chu·ªói kh√¥ng ph·∫£i key:value ho·∫∑c kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi s·ªë
            continue

    return metrics


# ----------------- FLASK API ENDPOINTS -----------------
app = Flask(__name__)

# 2. √Åp d·ª•ng CORS
CORS(app)


@app.route('/api/tiki-product', methods=['GET'])
def scrape_and_save():
    """Endpoint API: C√†o d·ªØ li·ªáu t·ª´ URL v√† L∆ØU/C·∫¨P NH·∫¨T v√†o Bi·∫øn Global."""
    print("--- API /tiki-product ƒê∆Ø·ª¢C G·ªåI ---")
    tiki_url = request.args.get('url')
    if not tiki_url:
        return jsonify({"error": "Vui l√≤ng cung c·∫•p URL s·∫£n ph·∫©m Tiki trong tham s·ªë 'url'."}), 400

    # 1. Th·ª±c hi·ªán c√†o d·ªØ li·ªáu
    result, status_code = process_tiki_url(tiki_url)

    if status_code != 200:
        return jsonify(result), status_code
    print("result: ", result)
    #  B∆Ø·ªöC 1: TR√çCH XU·∫§T C√ÅC CH·ªà S·ªê C·∫¶N THI·∫æT T·ª™ DANH S√ÅCH 'properties'
    res = extract_core_metrics(result)
    print("Metrics tr√≠ch xu·∫•t ƒë∆∞·ª£c (res):", res)

    # 2. L∆∞u v√†o Bi·∫øn Global
    success = save_to_global_store( tiki_url, result)

    if success:
        # IN TR·∫†NG TH√ÅI GLOBAL STORE ƒê·ªÇ XEM
        print("\n=============================================")
        print(f"‚úÖ L∆ØU/C·∫¨P NH·∫¨T th√†nh c√¥ng ID.")
        print(f"üìä T·ªïng s·ªë b·∫£n ghi trong SCRAPED_DATA_STORE hi·ªán t·∫°i: {len(SCRAPED_DATA_STORE)}")
        print(f"   B·∫£n ghi v·ª´a l∆∞u")
        print("=============================================")

        # B∆Ø·ªöC 2: TR·∫¢ V·ªÄ C√ÅC GI√Å TR·ªä ƒê√É ƒê∆Ø·ª¢C TR√çCH XU·∫§T T·ª™ 'res'
        return jsonify({
            "message": f"C√†o d·ªØ li·ªáu th√†nh c√¥ng v√† ƒë√£ L∆ØU/C·∫¨P NH·∫¨T v√†o Global Store .",
            "data_preview": {
                "name": result.get('name'),
                "price": res.get('price'),
                "rating_average": res.get('rating_average'),
                "review_count": res.get('review_count'),
                "sold_quantity": res.get('sold_quantity'),
                "image": result.get('image_product')[0]
            }
        }), 200
    else:
        return jsonify({"error": "L·ªói kh√¥ng x√°c ƒë·ªãnh khi l∆∞u v√†o Global Store."}), 500

@app.route('/api/get-data', methods=['GET'])
def get_saved_data():
    """Endpoint API: L·∫•y D·ªÆ LI·ªÜU G·∫¶N NH·∫§T ƒë√£ l∆∞u trong Bi·∫øn Global."""
    global SCRAPED_DATA_STORE

    if not SCRAPED_DATA_STORE:
        print("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o ƒë√£ ƒë∆∞·ª£c l∆∞u trong Global Store.")
        return jsonify({"message": "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o ƒë√£ ƒë∆∞·ª£c l∆∞u trong Global Store."}), 200

    # L·∫•y b·∫£n ghi cu·ªëi c√πng (v√† duy nh·∫•t)
    latest_record = SCRAPED_DATA_STORE[-1].copy()

    # L·∫•y th√¥ng tin chi ti·∫øt (information)
    data_content = latest_record['information']

    # In ra console
    print("\n=============================================")
    print("Y√™u c·∫ßu l·∫•y d·ªØ li·ªáu G·∫¶N NH·∫§T t·ª´ Global Store.")
    print(f"B·∫£n ghi ƒë∆∞·ª£c tr·∫£ v·ªÅ th√†nh c√¥ng")
    print("=============================================")

    # Tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng d·ªØ li·ªáu duy nh·∫•t
    return jsonify({
        "message": "D·ªØ li·ªáu c√†o g·∫ßn nh·∫•t ƒë√£ ƒë∆∞·ª£c l·∫•y th√†nh c√¥ng.",
"data": data_content
    }), 200

@app.route('/api/tiki', methods=['GET'])
def tiki_full_scrape():
    """API duy nh·∫•t: Nh·∫≠p URL s·∫£n ph·∫©m, tr·∫£ v·ªÅ t·∫•t c·∫£ d·ªØ li·ªáu v√† l∆∞u v√†o Global Store."""
    tiki_url = request.args.get('url')
    if not tiki_url:
        return jsonify({"error": "Vui l√≤ng cung c·∫•p URL s·∫£n ph·∫©m Tiki."}), 400

    # --- 1. X·ª≠ l√Ω URL v√† l·∫•y product_id ---
    product_id = extract_tiki_product_id(tiki_url)
    if not product_id:
        return jsonify({"error": "Kh√¥ng th·ªÉ l·∫•y product_id t·ª´ URL."}), 400

    # --- 2. L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m ---
    product_data = fetch_product_data(product_id, tiki_url)
    if not product_data:
        return jsonify({"error": "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m."}), 500
    parsed_product = parse_product_to_json(product_data)

    # --- 3. L·∫•y review ---
    reviews = fetch_reviews_data(product_id, desired_total=20)

    # --- 4. L·∫•y d·ªØ li·ªáu c·ª≠a h√†ng ---
    store_url = parsed_product.get("store_url")
    store_data = {}
    if store_url:
        final_store_url = f"{store_url}?t=storeInfo" if '?' not in store_url else f"{store_url}&t=storeInfo"
        store_data = fetch_store_data_selenium(final_store_url)
    else:
        store_data = {"error": "Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ª≠a h√†ng."}

    # --- 5. Build k·∫øt qu·∫£ ---
    product_properties = [f"{spec['name']}: {spec['value']}" for spec in parsed_product.get("specifications", [])]
    product_properties += [
        f"price: {parsed_product.get('price')}",
        f"rating_average: {parsed_product.get('rating_average')}",
        f"review_count: {parsed_product.get('review_count')}",
        f"sold_quantity: {parsed_product.get('sold_quantity')}"
    ]

    image_buyer_urls = list({
        img["full_path"]
        for r in reviews
        for img in r.get("images", [])
        if img.get("full_path")
    })

    result = {
        "store_data": store_data,
        "name": parsed_product.get("name"),
        "description": parsed_product.get("description_text"),
        "properties": product_properties,
        "image_product": parsed_product.get("description_images", []) + parsed_product.get("gallery_images", []),
        "image_buyer": image_buyer_urls,
        "reviews": [{"rating": r.get("rating"), "title": r.get("title"), "content": r.get("content")} for r in reviews]
    }

    # --- 6. L∆∞u v√†o Global Store ---
    save_to_global_store(tiki_url, result)

    # --- 7. Tr·∫£ v·ªÅ JSON full data ---
    return jsonify({
        "message": "C√†o d·ªØ li·ªáu th√†nh c√¥ng v√† ƒë√£ l∆∞u v√†o Global Store.",
        "full_data": result
    }), 200

if __name__ == '__main__':
    host = os.getenv("FLASK_HOST", "127.0.0.1")
    port = int(os.getenv("FLASK_PORT", 5000))

    print("\nKh·ªüi ch·∫°y Flask API (S·∫£n ph·∫©m, C·ª≠a h√†ng & Global Store).")
    print("----------------------------------------------------------------------")
    print("L∆ØU TR·ªÆ D·ªÆ LI·ªÜU: ƒêang s·ª≠ d·ª•ng bi·∫øn Global Store (trong b·ªô nh·ªõ).")
    print("H∆Ø·ªöNG D·∫™N: ƒê√£ s·ª≠ d·ª•ng use_reloader=False ƒë·ªÉ ƒë·∫£m b·∫£o bi·∫øn global ho·∫°t ƒë·ªông.")
    print("----------------------------------------------------------------------")
    print(f"1. C√ÄO & L∆ØU D·ªÆ LI·ªÜU: GET http://{host}:{port}/api/tiki-product?url=<Tiki_Product_URL>")
    print(f"2. L·∫§Y D·ªÆ LI·ªÜU V·ª™A L∆ØU: GET http://{host}:{port}/api/get-data")
    print("----------------------------------------------------------------------")

    # S·ª¨ D·ª§NG use_reloader=False ƒë·ªÉ ƒë·∫£m b·∫£o bi·∫øn global kh√¥ng b·ªã reset b·ªüi ti·∫øn tr√¨nh reloader
    app.run(debug=True, use_reloader=False, host=host, port=port)